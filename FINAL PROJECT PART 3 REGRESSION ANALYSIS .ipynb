{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fc3ddf-5451-46f6-8785-0c99981b5d79",
   "metadata": {},
   "source": [
    "Prediction and Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e40becf-3623-4f2c-9bea-75c18bb8ffe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     zip       date        price  t  month\n",
      "0  20001 2000-01-31  152793.9122  0      1\n",
      "1  20001 2000-02-29  153157.2965  1      2\n",
      "2  20001 2000-03-31  153360.9641  2      3\n",
      "3  20001 2000-04-30  154323.7478  3      4\n",
      "4  20001 2000-05-31  155195.4995  4      5\n",
      "\n",
      "Data shape: (6489, 5)\n",
      "\n",
      "Validation metrics by ZIP:\n",
      "     zip    naive_rmse  naive_mape      lin_rmse  lin_mape     poly_rmse  \\\n",
      "4  20005  10905.056184    0.017668  84812.022007  0.155115  16147.692699   \n",
      "8  20010  34910.494835    0.038441  31009.214776  0.036749  31388.463054   \n",
      "7  20009   8629.729607    0.012138  54257.849487  0.085505  24739.360856   \n",
      "9  20011  38861.730842    0.049998  68903.688391  0.091616  41011.596214   \n",
      "1  20002  18850.747820    0.023239  35517.959205  0.047615  51354.703717   \n",
      "\n",
      "   poly_mape  \n",
      "4   0.028626  \n",
      "8   0.037287  \n",
      "7   0.038854  \n",
      "9   0.052305  \n",
      "1   0.054390  \n",
      "\n",
      "Model choice per ZIP:\n",
      "      zip best_model  lin_mape  poly_mape\n",
      "0   20001       poly  0.160743   0.081603\n",
      "1   20002     linear  0.047615   0.054390\n",
      "2   20003     linear  0.033861   0.063689\n",
      "3   20004       poly  0.202761   0.087586\n",
      "4   20005       poly  0.155115   0.028626\n",
      "5   20007     linear  0.038527   0.144770\n",
      "6   20008     linear  0.028802   0.133201\n",
      "7   20009       poly  0.085505   0.038854\n",
      "8   20010     linear  0.036749   0.037287\n",
      "9   20011       poly  0.091616   0.052305\n",
      "10  20012     linear  0.110122   0.128339\n",
      "11  20015     linear  0.115635   0.205738\n",
      "12  20016     linear  0.097108   0.174053\n",
      "13  20017       poly  0.090470   0.057478\n",
      "14  20018       poly  0.117685   0.071605\n",
      "15  20019       poly  0.198472   0.117002\n",
      "16  20020       poly  0.187839   0.149584\n",
      "17  20024     linear  0.051217   0.058662\n",
      "18  20032       poly  0.246319   0.127456\n",
      "19  20036       poly  0.134789   0.061521\n",
      "20  20037       poly  0.112006   0.070653\n",
      "\n",
      "Sample of forecasted prices:\n",
      "     zip       date  predicted_price         model_type\n",
      "0  20001 2026-01-31    705190.911197  poly_trend_season\n",
      "1  20001 2026-02-28    704539.885502  poly_trend_season\n",
      "2  20001 2026-03-31    703875.876062  poly_trend_season\n",
      "3  20001 2026-04-30    703714.384717  poly_trend_season\n",
      "4  20001 2026-05-31    703535.761765  poly_trend_season\n",
      "\n",
      "Saved forecasts to DC_housing_forecast_2026_2027_by_zip.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/lq__dftn5yb18dj6bbxg48jw0000gn/T/ipykernel_1345/3389992662.py:28: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  long_df['date'] = pd.to_datetime(long_df['date'])\n",
      "/var/folders/2n/lq__dftn5yb18dj6bbxg48jw0000gn/T/ipykernel_1345/3389992662.py:155: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  future_dates = pd.date_range(start=\"2026-01-31\", end=\"2027-12-31\", freq=\"M\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load and reshape the data\n",
    "# -----------------------------\n",
    "#DATA_PATH = \"('/Users/sundeepravichander/OIM7502_F25/DC_housing_prices.csv') \" # change if needed\n",
    "\n",
    "df = pd.read_csv('/Users/sundeepravichander/OIM7502_F25/DC_housing_prices.csv')\n",
    "\n",
    "# Identify the date columns (Zillow format → dates start around column 9)\n",
    "date_cols = df.columns[9:]\n",
    "\n",
    "# Reshape from wide → long\n",
    "long_df = df.melt(\n",
    "    id_vars=['RegionName'],     # ZIP code column\n",
    "    value_vars=date_cols,       # all date columns\n",
    "    var_name='date',            # new date column\n",
    "    value_name='price'          # price values\n",
    ")\n",
    "\n",
    "# Clean & convert data types\n",
    "long_df['zip'] = long_df['RegionName'].astype(str)\n",
    "long_df['date'] = pd.to_datetime(long_df['date'])\n",
    "\n",
    "# Keep only what you need\n",
    "long_df = long_df[['zip', 'date', 'price']].sort_values(['zip', 'date']).reset_index(drop=True)\n",
    "\n",
    "# Create simple time-series features\n",
    "long_df['t'] = long_df.groupby('zip').cumcount()               # time index\n",
    "long_df['month'] = long_df['date'].dt.month                    # month (for seasonality)\n",
    "\n",
    "print(long_df.head())\n",
    "print(\"\\nData shape:\", long_df.shape)\n",
    "\n",
    "train_end = pd.to_datetime(\"2020-12-31\")\n",
    "val_end   = pd.to_datetime(\"2023-12-31\")\n",
    "\n",
    "def split_by_time(zip_df, train_end, val_end):\n",
    "    \"\"\"Split a single-zip dataframe into train / val / test by date.\"\"\"\n",
    "    train = zip_df[zip_df['date'] <= train_end].copy()\n",
    "    val   = zip_df[(zip_df['date'] > train_end) & (zip_df['date'] <= val_end)].copy()\n",
    "    test  = zip_df[zip_df['date'] > val_end].copy()\n",
    "    return train, val, test\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Helpers to build X, y\n",
    "# -----------------------------\n",
    "def build_regression_X(df_part, degree=1):\n",
    "    \"\"\"\n",
    "    Build design matrix:\n",
    "      - polynomial trend in t (degree 1 or 2)\n",
    "      - month dummies for seasonality\n",
    "    \"\"\"\n",
    "    df_part = df_part.reset_index(drop=True)\n",
    "    X = pd.DataFrame({'t': df_part['t'].values})\n",
    "    if degree >= 2:\n",
    "        X['t2'] = df_part['t'].values ** 2\n",
    "\n",
    "    # add month dummies (drop_first to avoid multicollinearity)\n",
    "    month_dummies = pd.get_dummies(df_part['month'], prefix='month', drop_first=True)\n",
    "    X = pd.concat([X, month_dummies], axis=1)\n",
    "    return X\n",
    "\n",
    "def evaluate_regression(train, val, degree):\n",
    "    \"\"\"Fit regression model of given degree and compute validation metrics.\"\"\"\n",
    "    if len(train) == 0 or len(val) == 0:\n",
    "        return None, np.nan, np.nan\n",
    "\n",
    "    X_train = build_regression_X(train, degree=degree)\n",
    "    X_val   = build_regression_X(val, degree=degree)\n",
    "\n",
    "    # Align columns in case some months are missing in val or train\n",
    "    X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    y_train = train['price'].values\n",
    "    y_val   = val['price'].values\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    val_pred = model.predict(X_val)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "    mape = mean_absolute_percentage_error(y_val, val_pred)\n",
    "\n",
    "    return model, rmse, mape\n",
    "\n",
    "def evaluate_naive(train, val):\n",
    "    \"\"\"Naive baseline: forecast = last observed value.\"\"\"\n",
    "    if len(train) == 0 or len(val) == 0:\n",
    "        return np.nan, np.nan\n",
    "\n",
    "    last_train_value = train['price'].iloc[-1]\n",
    "    y_val = val['price'].values\n",
    "    y_pred = np.full_like(y_val, fill_value=last_train_value, dtype=float)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_val, y_pred)\n",
    "    return rmse, mape\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Loop over zips and evaluate models\n",
    "# -----------------------------\n",
    "results = []\n",
    "\n",
    "for z in long_df['zip'].unique():\n",
    "    z_df = long_df[long_df['zip'] == z].copy().sort_values('date')\n",
    "    train, val, test = split_by_time(z_df, train_end, val_end)\n",
    "\n",
    "    # Baseline naive\n",
    "    naive_rmse, naive_mape = evaluate_naive(train, val)\n",
    "\n",
    "    # Linear trend + seasonality (degree=1)\n",
    "    lin_model, lin_rmse, lin_mape = evaluate_regression(train, val, degree=1)\n",
    "\n",
    "    # Polynomial trend + seasonality (degree=2)\n",
    "    poly_model, poly_rmse, poly_mape = evaluate_regression(train, val, degree=2)\n",
    "\n",
    "    results.append({\n",
    "        'zip': z,\n",
    "        'naive_rmse': naive_rmse,\n",
    "        'naive_mape': naive_mape,\n",
    "        'lin_rmse': lin_rmse,\n",
    "        'lin_mape': lin_mape,\n",
    "        'poly_rmse': poly_rmse,\n",
    "        'poly_mape': poly_mape\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(results)\n",
    "print(\"\\nValidation metrics by ZIP:\")\n",
    "print(metrics_df.sort_values('poly_mape').head())\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Choose best regression model per zip\n",
    "# -----------------------------\n",
    "def choose_best_model(row):\n",
    "    # choose lower MAPE between linear and polynomial\n",
    "    if row['poly_mape'] < row['lin_mape']:\n",
    "        return 'poly'\n",
    "    else:\n",
    "        return 'linear'\n",
    "\n",
    "metrics_df['best_model'] = metrics_df.apply(choose_best_model, axis=1)\n",
    "print(\"\\nModel choice per ZIP:\")\n",
    "print(metrics_df[['zip', 'best_model', 'lin_mape', 'poly_mape']])\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Refit best model on full history and forecast 2026–2027\n",
    "# -----------------------------\n",
    "future_dates = pd.date_range(start=\"2026-01-31\", end=\"2027-12-31\", freq=\"M\")\n",
    "forecast_rows = []\n",
    "\n",
    "for _, row in metrics_df.iterrows():\n",
    "    z = row['zip']\n",
    "    best = row['best_model']\n",
    "\n",
    "    z_df = long_df[long_df['zip'] == z].copy().sort_values('date')\n",
    "    # recompute t for safety\n",
    "    z_df['t'] = np.arange(len(z_df))\n",
    "    z_df['month'] = z_df['date'].dt.month\n",
    "\n",
    "    # fit on all available history up to last date\n",
    "    degree = 2 if best == 'poly' else 1\n",
    "    X_full = build_regression_X(z_df, degree=degree)\n",
    "    y_full = z_df['price'].values\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_full, y_full)\n",
    "\n",
    "    # build future features\n",
    "    last_t = z_df['t'].iloc[-1]\n",
    "    future_t = np.arange(last_t + 1, last_t + 1 + len(future_dates))\n",
    "    future_month = future_dates.month\n",
    "\n",
    "    future_df = pd.DataFrame({\n",
    "        't': future_t,\n",
    "        'month': future_month\n",
    "    })\n",
    "\n",
    "    X_future = build_regression_X(future_df, degree=degree)\n",
    "    # align cols with training X\n",
    "    X_future = X_future.reindex(columns=X_full.columns, fill_value=0)\n",
    "\n",
    "    future_pred = model.predict(X_future)\n",
    "\n",
    "    for d, p in zip(future_dates, future_pred):\n",
    "        forecast_rows.append({\n",
    "            'zip': z,\n",
    "            'date': d,\n",
    "            'predicted_price': p,\n",
    "            'model_type': f'{best}_trend_season'\n",
    "        })\n",
    "\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "print(\"\\nSample of forecasted prices:\")\n",
    "print(forecast_df.head())\n",
    "\n",
    "# Save to CSV: this is your final deliverable table\n",
    "forecast_df.to_csv(\"DC_housing_forecast_2026_2027_by_zip.csv\", index=False)\n",
    "print(\"\\nSaved forecasts to DC_housing_forecast_2026_2027_by_zip.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0254557-44da-454c-a2d3-93614822bc4c",
   "metadata": {},
   "source": [
    "Test multiple regression approaches (linear, polynomial, time-series models like ARIMA)\n",
    "\n",
    "Validate model performance and select best-performing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "308ba335-809d-4863-b4ac-f23166a6e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      zip  linear_mape  poly_mape  arima_mape\n",
      "0   20001     0.160743   0.081603    0.020553\n",
      "1   20002     0.047615   0.054390    0.023026\n",
      "2   20003     0.033861   0.063689    0.032627\n",
      "3   20004     0.202761   0.087586    0.016953\n",
      "4   20005     0.155115   0.028626    0.017625\n",
      "5   20007     0.038527   0.144770    0.076756\n",
      "6   20008     0.028802   0.133201    0.056907\n",
      "7   20009     0.085505   0.038854    0.012131\n",
      "8   20010     0.036749   0.037287    0.037723\n",
      "9   20011     0.091616   0.052305    0.048706\n",
      "10  20012     0.110122   0.128339    0.068035\n",
      "11  20015     0.115635   0.205738    0.115579\n",
      "12  20016     0.097108   0.174053    0.094045\n",
      "13  20017     0.090470   0.057478    0.033729\n",
      "14  20018     0.117685   0.071605    0.059161\n",
      "15  20019     0.198472   0.117002    0.038229\n",
      "16  20020     0.187839   0.149584    0.047101\n",
      "17  20024     0.051217   0.058662    0.026014\n",
      "18  20032     0.246319   0.127456    0.048643\n",
      "19  20036     0.134789   0.061521    0.023036\n",
      "20  20037     0.112006   0.070653    0.014949\n",
      "      zip  linear_mape  poly_mape  arima_mape best_model\n",
      "0   20001     0.160743   0.081603    0.020553      arima\n",
      "1   20002     0.047615   0.054390    0.023026      arima\n",
      "2   20003     0.033861   0.063689    0.032627      arima\n",
      "3   20004     0.202761   0.087586    0.016953      arima\n",
      "4   20005     0.155115   0.028626    0.017625      arima\n",
      "5   20007     0.038527   0.144770    0.076756     linear\n",
      "6   20008     0.028802   0.133201    0.056907     linear\n",
      "7   20009     0.085505   0.038854    0.012131      arima\n",
      "8   20010     0.036749   0.037287    0.037723     linear\n",
      "9   20011     0.091616   0.052305    0.048706      arima\n",
      "10  20012     0.110122   0.128339    0.068035      arima\n",
      "11  20015     0.115635   0.205738    0.115579      arima\n",
      "12  20016     0.097108   0.174053    0.094045      arima\n",
      "13  20017     0.090470   0.057478    0.033729      arima\n",
      "14  20018     0.117685   0.071605    0.059161      arima\n",
      "15  20019     0.198472   0.117002    0.038229      arima\n",
      "16  20020     0.187839   0.149584    0.047101      arima\n",
      "17  20024     0.051217   0.058662    0.026014      arima\n",
      "18  20032     0.246319   0.127456    0.048643      arima\n",
      "19  20036     0.134789   0.061521    0.023036      arima\n",
      "20  20037     0.112006   0.070653    0.014949      arima\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Time-based train/validation split\n",
    "train_end = pd.to_datetime(\"2020-12-31\")\n",
    "val_end   = pd.to_datetime(\"2023-12-31\")\n",
    "\n",
    "\n",
    "#Compute error metrics for each model\n",
    "def evaluate_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    return rmse, mape\n",
    "\n",
    "\n",
    "# LINEAR REGRESSION\n",
    "def run_linear_regression(train, val):\n",
    "    X_train = pd.get_dummies(train[['t','month']], columns=['month'], drop_first=True)\n",
    "    X_val   = pd.get_dummies(val[['t','month']],   columns=['month'], drop_first=True)\n",
    "    X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    y_train = train['price']\n",
    "    y_val   = val['price']\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "    rmse, mape = evaluate_metrics(y_val, preds)\n",
    "\n",
    "\n",
    "#POLYNOMIAL REGRESSION MODEL    \n",
    "\n",
    "    return model, rmse, mape\n",
    "def run_polynomial_regression(train, val):\n",
    "    train = train.copy()\n",
    "    val   = val.copy()\n",
    "\n",
    "    train['t2'] = train['t']**2\n",
    "    val['t2']   = val['t']**2\n",
    "\n",
    "    X_train = pd.get_dummies(train[['t','t2','month']], columns=['month'], drop_first=True)\n",
    "    X_val   = pd.get_dummies(val[['t','t2','month']],   columns=['month'], drop_first=True)\n",
    "    X_val = X_val.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    y_train = train['price']\n",
    "    y_val   = val['price']\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "    rmse, mape = evaluate_metrics(y_val, preds)\n",
    "\n",
    "    return model, rmse, mape\n",
    "\n",
    "#  ARIMA TIME SERIES MODEL\n",
    "    \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def run_arima(train, val, order=(1,1,0)):\n",
    "    series_train = train.set_index('date')['price']\n",
    "    series_val   = val.set_index('date')['price']\n",
    "\n",
    "    # Force real monthly frequency (month-end \"ME\")\n",
    "    series_train.index = pd.DatetimeIndex(series_train.index).to_period('M').to_timestamp('M')\n",
    "    series_val.index   = pd.DatetimeIndex(series_val.index).to_period('M').to_timestamp('M')\n",
    "\n",
    "    series_train = series_train.asfreq('ME')\n",
    "    series_val   = series_val.asfreq('ME')\n",
    "\n",
    "    # Fit ARIMA safely\n",
    "    model = sm.tsa.ARIMA(series_train, order=order)\n",
    "    fit = model.fit()\n",
    "\n",
    "    preds = fit.forecast(steps=len(series_val))\n",
    "\n",
    "    rmse, mape = evaluate_metrics(series_val.values, preds.values)\n",
    "    return fit, rmse, mape\n",
    "\n",
    "#Evaluation of 3 models\n",
    "results = []\n",
    "\n",
    "for z in long_df['zip'].unique():\n",
    "\n",
    "    z_df = long_df[long_df['zip'] == z].copy()\n",
    "    train = z_df[z_df['date'] <= train_end]\n",
    "    val   = z_df[(z_df['date'] > train_end) & (z_df['date'] <= val_end)]\n",
    "\n",
    "    # Model 1\n",
    "    lin_model, lin_rmse, lin_mape = run_linear_regression(train, val)\n",
    "\n",
    "    # Model 2\n",
    "    poly_model, poly_rmse, poly_mape = run_polynomial_regression(train, val)\n",
    "\n",
    "    # Model 3\n",
    "    arima_model, arima_rmse, arima_mape = run_arima(train, val)\n",
    "    \n",
    "#Select best-performing models\n",
    "    results.append({\n",
    "        'zip': z,\n",
    "        'linear_mape': lin_mape,\n",
    "        'poly_mape': poly_mape,\n",
    "        'arima_mape': arima_mape\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "\n",
    "def choose_model(row):\n",
    "    mape_scores = {\n",
    "        'linear': row['linear_mape'],\n",
    "        'poly': row['poly_mape'],\n",
    "        'arima': row['arima_mape']\n",
    "    }\n",
    "    return min(mape_scores, key=mape_scores.get)\n",
    "\n",
    "results_df['best_model'] = results_df.apply(choose_model, axis=1)\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d103a90-bf49-450d-ab12-580c9d632b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== SAMPLE OF ZIP-LEVEL FORECASTS (2026–2027) ======\n",
      "\n",
      "  zip       date  predicted_price model_used\n",
      "20001 2026-01-31    644986.511534      arima\n",
      "20001 2026-02-28    644966.359111      arima\n",
      "20001 2026-03-31    644962.908295      arima\n",
      "20001 2026-04-30    644962.317392      arima\n",
      "20001 2026-05-31    644962.216209      arima\n",
      "20001 2026-06-30    644962.198882      arima\n",
      "20001 2026-07-31    644962.195916      arima\n",
      "20001 2026-08-31    644962.195408      arima\n",
      "20001 2026-09-30    644962.195321      arima\n",
      "20001 2026-10-31    644962.195306      arima\n",
      "20001 2026-11-30    644962.195303      arima\n",
      "20001 2026-12-31    644962.195303      arima\n",
      "20001 2027-01-31    644962.195303      arima\n",
      "20001 2027-02-28    644962.195303      arima\n",
      "20001 2027-03-31    644962.195303      arima\n",
      "20001 2027-04-30    644962.195303      arima\n",
      "20001 2027-05-31    644962.195303      arima\n",
      "20001 2027-06-30    644962.195303      arima\n",
      "20001 2027-07-31    644962.195303      arima\n",
      "20001 2027-08-31    644962.195303      arima\n",
      "\n",
      "Saved: DC_ZIP_Forecasts_2026_2027.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>linear_mape</th>\n",
       "      <th>poly_mape</th>\n",
       "      <th>arima_mape</th>\n",
       "      <th>best_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>0.033861</td>\n",
       "      <td>0.063689</td>\n",
       "      <td>0.032627</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>0.047615</td>\n",
       "      <td>0.054390</td>\n",
       "      <td>0.023026</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20024</td>\n",
       "      <td>0.051217</td>\n",
       "      <td>0.058662</td>\n",
       "      <td>0.026014</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20009</td>\n",
       "      <td>0.085505</td>\n",
       "      <td>0.038854</td>\n",
       "      <td>0.012131</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20017</td>\n",
       "      <td>0.090470</td>\n",
       "      <td>0.057478</td>\n",
       "      <td>0.033729</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20011</td>\n",
       "      <td>0.091616</td>\n",
       "      <td>0.052305</td>\n",
       "      <td>0.048706</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20016</td>\n",
       "      <td>0.097108</td>\n",
       "      <td>0.174053</td>\n",
       "      <td>0.094045</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20012</td>\n",
       "      <td>0.110122</td>\n",
       "      <td>0.128339</td>\n",
       "      <td>0.068035</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20037</td>\n",
       "      <td>0.112006</td>\n",
       "      <td>0.070653</td>\n",
       "      <td>0.014949</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20015</td>\n",
       "      <td>0.115635</td>\n",
       "      <td>0.205738</td>\n",
       "      <td>0.115579</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20018</td>\n",
       "      <td>0.117685</td>\n",
       "      <td>0.071605</td>\n",
       "      <td>0.059161</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20036</td>\n",
       "      <td>0.134789</td>\n",
       "      <td>0.061521</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>0.155115</td>\n",
       "      <td>0.028626</td>\n",
       "      <td>0.017625</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>0.160743</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.020553</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20020</td>\n",
       "      <td>0.187839</td>\n",
       "      <td>0.149584</td>\n",
       "      <td>0.047101</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20019</td>\n",
       "      <td>0.198472</td>\n",
       "      <td>0.117002</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>0.202761</td>\n",
       "      <td>0.087586</td>\n",
       "      <td>0.016953</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20032</td>\n",
       "      <td>0.246319</td>\n",
       "      <td>0.127456</td>\n",
       "      <td>0.048643</td>\n",
       "      <td>arima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20008</td>\n",
       "      <td>0.028802</td>\n",
       "      <td>0.133201</td>\n",
       "      <td>0.056907</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20010</td>\n",
       "      <td>0.036749</td>\n",
       "      <td>0.037287</td>\n",
       "      <td>0.037723</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20007</td>\n",
       "      <td>0.038527</td>\n",
       "      <td>0.144770</td>\n",
       "      <td>0.076756</td>\n",
       "      <td>linear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      zip  linear_mape  poly_mape  arima_mape best_model\n",
       "2   20003     0.033861   0.063689    0.032627      arima\n",
       "1   20002     0.047615   0.054390    0.023026      arima\n",
       "17  20024     0.051217   0.058662    0.026014      arima\n",
       "7   20009     0.085505   0.038854    0.012131      arima\n",
       "13  20017     0.090470   0.057478    0.033729      arima\n",
       "9   20011     0.091616   0.052305    0.048706      arima\n",
       "12  20016     0.097108   0.174053    0.094045      arima\n",
       "10  20012     0.110122   0.128339    0.068035      arima\n",
       "20  20037     0.112006   0.070653    0.014949      arima\n",
       "11  20015     0.115635   0.205738    0.115579      arima\n",
       "14  20018     0.117685   0.071605    0.059161      arima\n",
       "19  20036     0.134789   0.061521    0.023036      arima\n",
       "4   20005     0.155115   0.028626    0.017625      arima\n",
       "0   20001     0.160743   0.081603    0.020553      arima\n",
       "16  20020     0.187839   0.149584    0.047101      arima\n",
       "15  20019     0.198472   0.117002    0.038229      arima\n",
       "3   20004     0.202761   0.087586    0.016953      arima\n",
       "18  20032     0.246319   0.127456    0.048643      arima\n",
       "6   20008     0.028802   0.133201    0.056907     linear\n",
       "8   20010     0.036749   0.037287    0.037723     linear\n",
       "5   20007     0.038527   0.144770    0.076756     linear"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 1) Define forecast period (month-end)\n",
    "future_dates = pd.date_range(start=\"2026-01-31\", end=\"2027-12-31\", freq=\"ME\")\n",
    "\n",
    "forecast_rows = []\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    z = row['zip']\n",
    "    best = row['best_model']\n",
    "\n",
    "    # Get full history for this ZIP\n",
    "    z_df = long_df[long_df['zip'] == z].copy().sort_values('date')\n",
    "\n",
    "    # Rebuild time features\n",
    "    z_df['t'] = np.arange(len(z_df))\n",
    "    z_df['month'] = z_df['date'].dt.month\n",
    "\n",
    "    # ---------------- LINEAR MODEL ----------------\n",
    "    if best == 'linear':\n",
    "        X_full = pd.get_dummies(z_df[['t', 'month']], columns=['month'], drop_first=True)\n",
    "        y_full = z_df['price'].values\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_full, y_full)\n",
    "\n",
    "        # future t and month\n",
    "        last_t = z_df['t'].iloc[-1]\n",
    "        future_t = np.arange(last_t + 1, last_t + 1 + len(future_dates))\n",
    "        future_months = future_dates.month\n",
    "\n",
    "        future_df = pd.DataFrame({'t': future_t, 'month': future_months})\n",
    "        X_future = pd.get_dummies(future_df, columns=['month'], drop_first=True)\n",
    "        X_future = X_future.reindex(columns=X_full.columns, fill_value=0)\n",
    "\n",
    "        preds = model.predict(X_future)\n",
    "\n",
    "    # -------------- POLYNOMIAL MODEL --------------\n",
    "    elif best == 'poly':\n",
    "        z_df['t2'] = z_df['t']**2\n",
    "\n",
    "        X_full = pd.get_dummies(z_df[['t', 't2', 'month']], columns=['month'], drop_first=True)\n",
    "        y_full = z_df['price'].values\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_full, y_full)\n",
    "\n",
    "        last_t = z_df['t'].iloc[-1]\n",
    "        future_t = np.arange(last_t + 1, last_t + 1 + len(future_dates))\n",
    "        future_df = pd.DataFrame({\n",
    "            't': future_t,\n",
    "            't2': future_t**2,\n",
    "            'month': future_dates.month\n",
    "        })\n",
    "\n",
    "        X_future = pd.get_dummies(future_df, columns=['month'], drop_first=True)\n",
    "        X_future = X_future.reindex(columns=X_full.columns, fill_value=0)\n",
    "\n",
    "        preds = model.predict(X_future)\n",
    "\n",
    "    # ------------------ ARIMA MODEL ----------------\n",
    "    elif best == 'arima':\n",
    "        # price as a time series\n",
    "        series = z_df.set_index('date')['price']\n",
    "\n",
    "        # make sure index is proper month-end freq\n",
    "        series.index = pd.DatetimeIndex(series.index).to_period('M').to_timestamp('M')\n",
    "        series = series.asfreq('ME')\n",
    "\n",
    "        # fit ARIMA with same order you used in run_arima\n",
    "        model = sm.tsa.ARIMA(series, order=(1, 1, 0)).fit()\n",
    "\n",
    "        preds = model.forecast(steps=len(future_dates))\n",
    "\n",
    "    # collect forecasts for this ZIP\n",
    "    for d, p in zip(future_dates, preds):\n",
    "        forecast_rows.append({\n",
    "            'zip': z,\n",
    "            'date': d,\n",
    "            'predicted_price': float(p),\n",
    "            'model_used': best\n",
    "        })\n",
    "\n",
    "# 2) Final forecast table\n",
    "forecast_df = pd.DataFrame(forecast_rows)\n",
    "forecast_df = forecast_df.sort_values(['zip', 'date']).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n====== SAMPLE OF ZIP-LEVEL FORECASTS (2026–2027) ======\\n\")\n",
    "print(forecast_df.head(20).to_string(index=False))\n",
    "\n",
    "# 3) Save to CSV for your team/report\n",
    "forecast_df.to_csv(\"DC_ZIP_Forecasts_2026_2027.csv\", index=False)\n",
    "print(\"\\nSaved: DC_ZIP_Forecasts_2026_2027.csv\")\n",
    "\n",
    "\n",
    "results_df.sort_values([\"best_model\", \"linear_mape\", \"poly_mape\", \"arima_mape\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a45ba518-acaa-44cd-ad89-66ee39098ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      zip    linear_rmse  linear_mape      poly_rmse  poly_mape  \\\n",
      "0   20001  119051.013889     0.160743   63426.348032   0.081603   \n",
      "1   20002   35517.959205     0.047615   51354.703717   0.054390   \n",
      "2   20003   33743.172380     0.033861   60855.160964   0.063689   \n",
      "3   20004   95289.243282     0.202761   41489.467416   0.087586   \n",
      "4   20005   84812.022007     0.155115   16147.692699   0.028626   \n",
      "5   20007   52137.875810     0.038527  175339.916250   0.144770   \n",
      "6   20008   32113.329462     0.028802  113596.972981   0.133201   \n",
      "7   20009   54257.849487     0.085505   24739.360856   0.038854   \n",
      "8   20010   31009.214776     0.036749   31388.463054   0.037287   \n",
      "9   20011   68903.688391     0.091616   41011.596214   0.052305   \n",
      "10  20012   91279.810551     0.110122  105328.762212   0.128339   \n",
      "11  20015  156429.627390     0.115635  274451.041298   0.205738   \n",
      "12  20016  108151.442614     0.097108  190590.965904   0.174053   \n",
      "13  20017   59843.853362     0.090470   39172.971355   0.057478   \n",
      "14  20018   73836.726679     0.117685   48992.245785   0.071605   \n",
      "15  20019   81366.502700     0.198472   51077.960966   0.117002   \n",
      "16  20020   78198.979924     0.187839   63135.373906   0.149584   \n",
      "17  20024   25122.840547     0.051217   33413.552261   0.058662   \n",
      "18  20032   91584.292644     0.246319   50234.142643   0.127456   \n",
      "19  20036   53876.157837     0.134789   24407.759134   0.061521   \n",
      "20  20037   68652.189339     0.112006   41847.945955   0.070653   \n",
      "\n",
      "       arima_rmse  arima_mape  \n",
      "0    16445.914684    0.020553  \n",
      "1    18616.484063    0.023026  \n",
      "2    33810.788273    0.032627  \n",
      "3    10891.608100    0.016953  \n",
      "4    10881.851425    0.017625  \n",
      "5    98419.757267    0.076756  \n",
      "6    52424.314569    0.056907  \n",
      "7     8624.362274    0.012131  \n",
      "8    34429.486483    0.037723  \n",
      "9    38064.721855    0.048706  \n",
      "10   58851.555800    0.068035  \n",
      "11  162246.463401    0.115579  \n",
      "12  109620.606917    0.094045  \n",
      "13   24348.448620    0.033729  \n",
      "14   39000.444467    0.059161  \n",
      "15   17266.252489    0.038229  \n",
      "16   21022.798742    0.047101  \n",
      "17   14741.141113    0.026014  \n",
      "18   19564.402492    0.048643  \n",
      "19   10163.914503    0.023036  \n",
      "20    9748.934463    0.014949  \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for z in long_df['zip'].unique():\n",
    "\n",
    "    z_df = long_df[long_df['zip'] == z].copy()\n",
    "    train = z_df[z_df['date'] <= train_end]\n",
    "    val   = z_df[(z_df['date'] > train_end) & (z_df['date'] <= val_end)]\n",
    "\n",
    "    # Model 1\n",
    "    lin_model, lin_rmse, lin_mape = run_linear_regression(train, val)\n",
    "\n",
    "    # Model 2\n",
    "    poly_model, poly_rmse, poly_mape = run_polynomial_regression(train, val)\n",
    "\n",
    "    # Model 3\n",
    "    arima_model, arima_rmse, arima_mape = run_arima(train, val)\n",
    "\n",
    "    results.append({\n",
    "        'zip': z,\n",
    "        'linear_rmse': lin_rmse,\n",
    "        'linear_mape': lin_mape,\n",
    "        'poly_rmse': poly_rmse,\n",
    "        'poly_mape': poly_mape,\n",
    "        'arima_rmse': arima_rmse,\n",
    "        'arima_mape': arima_mape\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54e4ee2-5d64-4214-86a7-fc3d62eb8bd9",
   "metadata": {},
   "source": [
    "In order to keep the models clean and realistic we had to make a few assumptions. \n",
    "Main one being that we assume that the historical price patterns we see in Zillow like the  upward trends the monthly fluctuations would continue even during  2026 & 2027. Each ZIP code was treated as its own market, as not every neighborhood behaves in a similar manner.\n",
    "For the regression model we assumed that the housing prices will change with time and seasonality, while in cotrast the ARIMA model assumes that they will become stabel when we get rid of the long term drift. \n",
    "\n",
    "At the same time, the models do have limitiations as does everything else. While forecasting for two years does the models cant  anticipate uncertainty and unexpected events like interest-rate changes or economic shocks or global geopolitical  situations that  can shift the market in ways the model cannot comprehend.Our models only use historical price data and don’t directly include outside factors such as mortgage rates, supply constraints, or policy changes, which can all affect housing markets. Polynomial models can sometimes over-interpret noise as curvature, and ARIMA can struggle to converge or capture long-term upward trends. We minimized these issues by validating everything on recent years rather than just trusting the fit on the full dataset.\n",
    "\n",
    "In order to  measure  the true performance of each model,  RMSE(Root Mean Square Error) & MAPE (Mean Absolute Percentage Error) were used as metrics for the comparison. The RMSE tells us how far off the predictions were in $s. MAPE expresses the erroe as a percentage , thus making it easy to compare ZIP codes with different price levels in a more simpler manner. The dataset was trained on 3 models namely Linear, Polynomial and ARIMA. This used data through 2020 and validated the same across the 2021-2023 period.Overall, most ZIP codes showed average errors in the 3–7% range, which indicates solid predictive performance. After selecting the best model for each ZIP, we used it to generate month-by-month forecasts for 2026 and 2027. \n",
    "\n",
    "Based on the  results,we can conclude that ARIMA  achieved the lowest  (MAPE) for most of the ZIP codes and is the most suitable model. This indicates that DC housing prices exhibit strong month-to-month autocorrelation patterns, which ARIMA captures more effectively than linear or polynomial trend models. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
